================================================================================
        CAUSAL VOLATILITY TRANSMISSION - SYSTEM ARCHITECTURE
================================================================================

┌─────────────────────────────────────────────────────────────────────────────┐
│                           DATA FLOW PIPELINE                                 │
└─────────────────────────────────────────────────────────────────────────────┘

INPUT DATA (HF_Returns_Stocks.csv)
│
│   5-minute stock returns for 300 stocks
│   Time period: 2004-2016
│   ~500k time intervals
│
▼
┌──────────────────────────────────────┐
│   DATA PREPROCESSING                  │
│   (data/dataloader.py)                │
│                                       │
│   • Load CSV data                     │
│   • Handle missing values             │
│   • Compute realized volatility       │
│     (1-hour rolling window)           │
│   • Z-score normalization per stock   │
│   • Create sequences (lookback=12)    │
│   • Chronological train/val/test split│
└──────────────────────────────────────┘
│
│   Sequences: (n_samples, 12 intervals, N stocks)
│   Targets: (n_samples, N stocks)
│
▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                        ATTENTION-BASED CAUSAL MODEL                           │
│                     (models/attention_model.py)                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  INPUT LAYER                                                                  │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │ Historical Returns: (batch, 12, N)  →  Embedding: (batch, 12, N, 64) │   │
│  │ Current Volatility: (batch, N)      →  Target Emb: (batch, 64)       │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                               │
│  LEARNED LAG ATTENTION MECHANISM                                              │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                                                                        │   │
│  │  For each source stock j:                                             │   │
│  │                                                                        │   │
│  │    1. Learned Lag Parameter: τ_j ∈ [0, 12] intervals                 │   │
│  │       └─> Determines when stock j's info arrives at target            │   │
│  │                                                                        │   │
│  │    2. Causal Gate: g_j ∈ [0, 1]                                       │   │
│  │       └─> Controls if stock j influences target                       │   │
│  │                                                                        │   │
│  │    3. Attention Mechanism:                                             │   │
│  │       Query (target):  q_i = W_q · target_emb                         │   │
│  │       Key (source):    k_j = W_k · stock_emb[t-τ_j]                   │   │
│  │       Value (source):  v_j = W_v · stock_emb[t-τ_j]                   │   │
│  │                                                                        │   │
│  │       Score: s_j = (q_i · k_j / √d_k) × g_j                           │   │
│  │       Attention: α = softmax(s_1, s_2, ..., s_N)                      │   │
│  │                                                                        │   │
│  │    4. Context Vector:                                                  │   │
│  │       c = Σ α_j · v_j                                                  │   │
│  │                                                                        │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                               │
│  PREDICTION HEAD (MLP)                                                        │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                                                                        │   │
│  │   [context + target_emb] → Linear(128) → ReLU → Dropout               │   │
│  │                          → Linear(64)  → ReLU → Dropout               │   │
│  │                          → Linear(1)   → Volatility Prediction        │   │
│  │                                                                        │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                               │
└──────────────────────────────────────────────────────────────────────────────┘
│
│   Outputs: • Predicted volatility
│            • Attention weights (which stocks matter)
│            • Causal gates (sparse influence structure)
│            • Learned lags (temporal alignment)
│
▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                           LOSS FUNCTION                                       │
│                        (utils/losses.py)                                      │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│   L = MSE(prediction, target)         ← Prediction accuracy                  │
│     + λ · ||g||_{2,1}                 ← Gate sparsity (L2,1 norm)            │
│     + γ · TV(α)                       ← Attention smoothness                 │
│     + η · IRM                         ← Invariant risk minimization          │
│                                                                               │
│   Default: λ=0.01, γ=0.001, η=0.001                                          │
│                                                                               │
└──────────────────────────────────────────────────────────────────────────────┘
│
│   Backpropagation → Update weights
│
▼
┌──────────────────────────────────────┐
│   TRAINING LOOP (train.py)            │
│                                       │
│   • Adam optimizer (lr=0.001)         │
│   • Batch size: 32                    │
│   • Gradient clipping: max_norm=1.0   │
│   • Early stopping (patience=10)      │
│   • Save best model checkpoint        │
└──────────────────────────────────────┘
│
│   Trained model → checkpoints/STOCK_best.pt
│
▼
┌──────────────────────────────────────────────────────────────────────────────┐
│                      CAUSAL ANALYSIS & VISUALIZATION                          │
│                       (analyze_causality.py)                                  │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│   EXTRACT CAUSAL GRAPH                                                        │
│   ┌────────────────────────────────────────────────────────────────────┐    │
│   │ For target stock i:                                                 │    │
│   │   • Gates: g_j (j=1..N) → Which stocks influence i                 │    │
│   │   • Lags: τ_j (j=1..N)  → Time delays of influence                 │    │
│   │   • Threshold: g_j > 0.1 → Significant relationships               │    │
│   └────────────────────────────────────────────────────────────────────┘    │
│                                                                               │
│   GENERATE OUTPUTS                                                            │
│   ┌────────────────────────────────────────────────────────────────────┐    │
│   │ 1. Console Report:                                                  │    │
│   │    • Table of top influencing stocks                                │    │
│   │    • Statistics (mean strength, lag distribution)                   │    │
│   │                                                                      │    │
│   │ 2. CSV Export:                                                       │    │
│   │    • results/STOCK_causal_relationships.csv                         │    │
│   │    • Columns: source, target, strength, lag                         │    │
│   │                                                                      │    │
│   │ 3. Visualizations (plots/):                                          │    │
│   │    • Causal network bar chart                                        │    │
│   │    • Lag distribution histogram                                      │    │
│   │    • Causal strength heatmap                                         │    │
│   └────────────────────────────────────────────────────────────────────┘    │
│                                                                               │
└──────────────────────────────────────────────────────────────────────────────┘

================================================================================
                         USER INTERFACE WORKFLOW
================================================================================

┌─────────────────────────────────────────────────────────────────────────────┐
│                       run_analysis.py (Main Entry Point)                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   COMMAND 1: List Stocks                                                     │
│   ───────────────────────                                                    │
│   $ python run_analysis.py --list                                            │
│   │                                                                           │
│   └─> Displays available stock tickers                                       │
│                                                                              │
│   COMMAND 2: Train Model                                                     │
│   ──────────────────────                                                     │
│   $ python run_analysis.py --train --stock AAPL --num_stocks 50              │
│   │                                                                           │
│   ├─> Load & preprocess data                                                 │
│   ├─> Initialize model                                                       │
│   ├─> Train with regularization                                              │
│   └─> Save checkpoint                                                        │
│                                                                              │
│   COMMAND 3: Analyze Causality                                               │
│   ────────────────────────────                                               │
│   $ python run_analysis.py --analyze --stock AAPL                            │
│   │                                                                           │
│   ├─> Load trained model                                                     │
│   ├─> Extract causal graph                                                   │
│   ├─> Generate report                                                        │
│   └─> Create visualizations                                                  │
│                                                                              │
│   COMMAND 4: One-Shot (Train + Analyze)                                      │
│   ──────────────────────────────────────                                     │
│   $ python run_analysis.py --train --analyze --stock AAPL --num_stocks 50    │
│   │                                                                           │
│   └─> Does both training and analysis in sequence                            │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

================================================================================
                            MODULE DEPENDENCIES
================================================================================

config.py
  └─> Configuration parameters (model, training, regularization)

data/
  ├─> __init__.py
  └─> dataloader.py
       ├─> StockDataLoader (loads CSV, computes volatility, normalizes)
       └─> VolatilityDataset (PyTorch Dataset)

models/
  ├─> __init__.py
  └─> attention_model.py
       ├─> LearnedLagAttention (attention with learned lags and gates)
       └─> CausalAttentionModel (full model architecture)

utils/
  ├─> __init__.py
  ├─> losses.py
  │    └─> CausalRegularizedLoss (MSE + gate + TV + IRM)
  └─> metrics.py
       └─> calculate_metrics (RMSE, MAE, R²)

train.py
  └─> Trainer class (training loop, checkpointing, validation)

analyze_causality.py
  └─> CausalityAnalyzer (extract graphs, generate reports, visualize)

run_analysis.py
  └─> Main CLI interface (orchestrates all components)

================================================================================
                          KEY DESIGN PATTERNS
================================================================================

1. MODULARITY
   • Clear separation: data / models / utils / training / analysis
   • Easy to extend or replace components

2. CONFIGURATION
   • Single config.py for all hyperparameters
   • No hardcoded magic numbers in code

3. PYTHONIC INTERFACES
   • Classes with clear responsibilities
   • Type hints for better documentation
   • Docstrings for all functions

4. USER-FRIENDLY CLI
   • Simple commands for complex operations
   • Helpful error messages
   • Progress bars (tqdm)

5. REPRODUCIBILITY
   • Chronological train/val/test splits
   • Checkpointing best models
   • Save all hyperparameters with results

6. INTERPRETABILITY
   • Attention weights show "what"
   • Causal gates show "which"
   • Learned lags show "when"
   • All are saved and visualized

================================================================================
                         THEORETICAL FOUNDATION
================================================================================

ATTENTION MECHANISM (Vaswani et al., 2017)
  • Query: "What info does target stock need?"
  • Key: "What info does source stock have?"
  • Value: "Actual information to transfer"

LEARNED LAGS (Novel Contribution)
  • Traditional: Fixed lag or grid search
  • This work: End-to-end learned τ_j parameters
  • Allows heterogeneous delays across stock pairs

CAUSAL GATES (Novel Contribution)
  • Traditional: Dense attention (all stocks matter)
  • This work: Sparse gates with L2,1 regularization
  • Interpretable: g_j ≈ 0 means j doesn't influence i

REGULARIZATION
  • Sparsity (L2,1): Prevents overfitting, aids interpretation
  • Smoothness (TV): Temporal coherence in attention
  • Invariance (IRM): Stable across market regimes

================================================================================
                          INNOVATION SUMMARY
================================================================================

✓ Joint learning of:
    - Prediction (volatility forecasting)
    - Discovery (causal structure)
    - Alignment (temporal lags)

✓ End-to-end differentiable:
    - No two-stage process
    - All parameters optimized together

✓ Interpretable by design:
    - Sparse gates → which stocks
    - Attention weights → how much
    - Learned lags → when

✓ Scalable:
    - Handles hundreds of stocks
    - Efficient attention computation

✓ Practical:
    - Easy-to-use interface
    - Comprehensive visualizations
    - Ready for deployment

================================================================================

