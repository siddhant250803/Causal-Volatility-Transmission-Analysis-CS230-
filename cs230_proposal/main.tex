\documentclass[11pt]{article}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{float}

\titleformat{\section}{\bfseries\Large}{\thesection.}{1em}{}
\titleformat{\subsection}{\bfseries\large}{\thesubsection.}{1em}{}

\title{\textbf{Mapping Intraday Volatility Transmission Across 300 Stocks Using Attention-Based Causal Inference}}
\author{Siddhant Sukhani \and Alexandre Roger \and Mahmood Alhusseini}
\date{}

\begin{document}

\maketitle
\doublespacing

\section{Introduction and Motivation}

Modern equity markets are deeply interconnected. A shock in one stock---such as a large sell order in a major index constituent---can ripple across related firms, sectors, or the broader market within minutes. These interactions occur rapidly due to algorithmic trading, order-book liquidity propagation, and correlated information flows. Traditional econometric models, typically operating on daily or hourly data, fail to capture these \textit{intraday causal dynamics} that govern volatility transmission in real time.

Understanding these micro-temporal dependencies is critical for several reasons:
\begin{itemize}[noitemsep]
    \item \textbf{Intraday risk management:} anticipating cross-stock volatility spikes.
    \item \textbf{High-frequency portfolio allocation:} reducing exposure to correlated shocks.
    \item \textbf{Market microstructure research:} uncovering sectoral and systemic information flow channels.
\end{itemize}

We propose an attention-based causal inference framework that learns how volatility shocks propagate among 300 large-cap U.S. equities sampled every 5 minutes. The model identifies which stocks influence others and quantifies both the \textit{direction} and \textit{lag structure} of those influences.

\section{Problem Description}

Given high-frequency log-returns
\[
r_{i,t} = \log\left(\frac{P_{i,t}}{P_{i,t-1}}\right),
\]
for \(N = 300\) stocks over 5-minute intervals, the goal is to predict short-term realized volatility:
\[
\hat{\sigma}_{i,t+1} = f\left(\{r_{j,t-\tau_j:t}\}_{j=1}^N\right),
\]
where \(\tau_j\) is a learned lag denoting how long it takes for movements in stock \(j\) to influence stock \(i\).

The objectives are:
\begin{enumerate}[noitemsep]
    \item Forecast next-interval (5-minute-ahead or 1-hour-ahead) realized volatility for each stock.
    \item Recover a directed causal graph of volatility transmission among stocks with adaptive time lags.
\end{enumerate}

\section{Challenges}

\begin{itemize}[noitemsep]
    \item \textbf{High-frequency noise:} microstructure effects such as bid-ask bounce and order clustering.
    \item \textbf{Extreme dimensionality:} 300 equities $\times$ thousands of 5-minute intervals.
    \item \textbf{Lag heterogeneity:} some pairs react instantaneously while others show delayed feedback.
    \item \textbf{Nonstationarity:} relationships evolve with regime shifts (e.g., earnings, macro news).
    \item \textbf{Interpretability:} standard neural models fail to reveal causal or sectoral pathways.
\end{itemize}

\section{Dataset}

\subsection{Data Sources}

\begin{itemize}[noitemsep]
    \item \textbf{Price \& volume:} 5-minute returns data from Professor \href{https://mpelger.people.stanford.edu/data-and-code}{Markus Pelger's website}.
    \item \textbf{Universe:} S\&P 300 constituents (large-cap and mid-cap U.S. equities).
    \item \textbf{Period:} 2004--2016 (approx.\ 500k intervals per stock).
\end{itemize}

\subsection{Target Variable}

Realized volatility is computed over a rolling window of \(n = 12\) intervals (approximately 1 hour):
\[
\sigma_{i,t} = \sqrt{\frac{1}{n}\sum_{k=1}^n r_{i,t-k}^2 }.
\]

\section{Preprocessing}

\begin{itemize}[noitemsep]
    \item Compute log-returns and realized volatility at 5-minute granularity.
    \item Apply z-score normalization per stock.
    \item Remove overnight gaps and low-liquidity periods.
    \item Handle missing ticks via Kalman or spline interpolation.
    \item Introduce learnable lag parameters \(\tau_j\) for temporal alignment.
    \item Chronological split (70\% / 15\% / 15\%) with walk-forward validation.
\end{itemize}
\section{Learning Method}

\subsection{Model Architecture}

For each stock \(i\), the model predicts its next-interval realized volatility using its own recent 5-minute data and attention-weighted information from other stocks:
\[
\hat{\sigma}_{i,t+1} = \text{MLP}\big([c_{i,t},\, r_{i,t}]\big),
\]
where \(r_{i,t}\) denotes the recent log returns of stock \(i\), and \(c_{i,t}\) represents the aggregated influence from other stocks via the attention mechanism. The multi-layer perceptron (MLP) learns to combine these components nonlinearly to forecast volatility.

Intuitively, the model for each stock learns how much of its future volatility can be explained by its own past versus the lagged signals arriving from other correlated equities.

\subsection{Lagged Attention Mechanism}

The attention mechanism identifies which other stocks influence a given stock’s volatility, with what delay, and to what magnitude.

\paragraph{Lagged Histories.}
For each stock \(j\), we construct a lagged sequence of past returns:
\[
H_{j,t} = [r_{j,t-1}, r_{j,t-2}, \ldots, r_{j,t-L}],
\]
where \(L\) is the lookback window length (e.g., 12 intervals ≈ 1 hour of 5-minute data).

\paragraph{Attention Weights.}
To determine which stocks and time lags are most relevant to predicting stock \(i\)’s volatility, the model computes attention weights:
\[
\alpha_{i\leftarrow j,t} = \text{softmax}\!\left(\frac{q_i^\top k_{j,t-\tau_j}}{\sqrt{d_k}}\right),
\]
where \(q_i\) and \(k_{j,t-\tau_j}\) are the query and key vectors for stocks \(i\) and \(j\), respectively, and \(\tau_j\) is a learned lag (in 5-minute units) that represents how long it takes for changes in stock \(j\) to influence stock \(i\). The softmax operation normalizes the weights across all potential sources.

\paragraph{Aggregation.}
The attention-weighted information from all other stocks is aggregated into a context vector:
\[
c_{i,t} = \sum_{j,\ell} g_j\,\alpha_{i\leftarrow j,t}\,v_{j,\ell,t-\tau_j},
\]
where \(v_{j,\ell,t-\tau_j}\) are value vectors containing encoded features of stock \(j\)’s lagged returns, \(\alpha_{i\leftarrow j,t}\) are the attention weights, and \(g_j\) is a causal gate that controls whether stock \(j\) exerts influence on others. The gates promote sparsity so that only a small subset of stocks drive cross-volatility effects.

This design enables the model to learn a directed and lagged network of volatility transmission among equities, uncovering causal structure dynamically as market conditions evolve.

\subsection{Causal Regularization}

To prevent overfitting and ensure interpretability, the total loss function includes several regularization components:
\[
\mathcal{L}
= \text{MSE}(\hat{\sigma}, \sigma)
+ \lambda \|g\|_{2,1}
+ \gamma\,\text{TV}(\alpha)
+ \eta\,\text{IRM},
\]
where:

\begin{itemize}[noitemsep]
    \item \(\text{MSE}(\hat{\sigma}, \sigma)\): mean squared error ensuring predictive accuracy.
    \item \(\lambda \|g\|_{2,1}\): group-lasso penalty encouraging a sparse set of active causal gates \(g_j\).
    \item \(\gamma\,\text{TV}(\alpha)\): total variation penalty promoting temporal smoothness in attention weights.
    \item \(\eta\,\text{IRM}\): invariant risk minimization term ensuring stability of learned relations across regimes.
\end{itemize}

This formulation yields sparse, interpretable, and stable causal dependencies between stocks, producing lag structures that remain consistent across varying market conditions.

\section{Evaluation}

\subsection{Baselines}

\begin{itemize}[noitemsep]
    \item High-dimensional Vector Autoregression (VAR) with Granger causality.
    \item Long Short-Term Memory (LSTM) without explicit lag modeling.
    \item Standard Transformer without causal regularization.
\end{itemize}

\subsection{Metrics}

\begin{itemize}[noitemsep]
    \item RMSE, MAE, and directional accuracy.
    \item Diebold--Mariano test for statistical significance.
\end{itemize}

\subsection{Causal Validation}

\begin{itemize}[noitemsep]
    \item Masking test: remove influential stock and assess impact on prediction.
    \item Permutation test and rolling-window stability analysis.
\end{itemize}

\subsection{Economic Evaluation}

\begin{itemize}[noitemsep]
    \item Volatility-targeted intraday portfolio backtesting.
    \item Stress-period propagation analysis (e.g., sector-wide shock diffusion).
    \item Visualization of dynamic causal graphs between correlated sectors (e.g., technology, energy).
\end{itemize}

\section{Expected Results}

\begin{itemize}[noitemsep]
    \item 5--10\% improvement in intraday volatility forecasting relative to benchmarks.
    \item Interpretable causal graphs showing lagged dependencies (e.g., AAPL $\rightarrow$ NVDA with 10-min lag).
    \item Regime-consistent propagation patterns between sectors.
    \item Scalable framework for high-frequency volatility prediction.
\end{itemize}

\section{Conclusion}

This project extends attention-based causal inference to high-frequency equity markets, modeling how volatility shocks propagate across hundreds of stocks in near real time. By learning both the \textit{direction} and \textit{timing} of influence, the approach enables interpretable, data-driven insight into market microstructure and supports risk-aware intraday trading strategies.

\end{document}
